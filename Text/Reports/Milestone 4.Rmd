
---
title: "STAT394 Group Project Milestone 4"
author: "Ken MacIver, Tom Tribe, Jundi Yang, Mei Huang"
date: "`r Sys.Date()`"
classoption: 12pt
output: bookdown::pdf_document2
bibliography: ./MASTER.bib
header-includes: \usepackage{float}
                    \floatplacement{figure}{H}
                    \floatplacement{table}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, message=FALSE}
# load the required packages
require(ggplot2)
require(ggthemes)
library(ggstance)
library(ggcorrplot)
library(ggplot2)
library(mvtnorm)
library(fitdistrplus)
library(GGally)
library(ggExtra)
library(reshape2)
library(xtable)
library(moments)
library(psych)
library(Hotelling)
library(car)
library(HDtest)
library(ggpubr)
options(xtable.floating = FALSE)
options(xtable.timestamp = "")

```

# The 'diamonds' dataset

NOTE: The size of this dataset means that rendering to PDF takes a long time.

For the STAT394 Group Project, Group 11 have chosen a dataset called 'diamonds', which presents data on 53940 diamonds. It was accessed it from kaggle.com. There are ten variables:

-   carat: the diamond's weight (numerical: 0.2 - 5.01)
-   cut: a measure of quality (categorical: Fair, Good, Very Good, Premium, Ideal)\
-   color: a measure of colour quality (categorical: J, which is poorest quality, to D, which is best, so J, I, H, G, F, E, D)
-   clarity: a measure of clearness (categorical: from worst to best = I1, SI2, SI1, VS2, VS1, VVS2, VVS1, IF)
-   x: length in mm (0 - 10.74)
-   y: width in mm (0 - 58.9) 
-   z: depth in mm (0 - 31.8)
-   depth: total depth percentage = z/mean(x,y) = 2\*z/(x+y) (43 - 79)
-   table: width of top of diamond relative to widest point
-   price: the price of the diamond in US dollars (List adapted from the list at @diamondskaggle). 

We are most interested in how these variables relate to and predict diamond price.

### Load the dataset into R.

```{r, echo=FALSE}

diamonds <- read.csv("./diamonds.csv", encoding = "UTF-8")
diamonds[1:5,]

# remove the index column
diamonds$X <- NULL

# get an overview of the structure of the data
str(diamonds)
```

## Create factor levels and view summary

```{r, echo=FALSE}
# set categorical variables as factors and set levels
diamonds$cut <- factor(diamonds$cut, 
                       levels = c("Fair","Good","Very Good","Premium","Ideal"))
diamonds$color <- factor(diamonds$color, 
                         levels = c("J","I","H","G","F","E","D"))
diamonds$clarity <- factor(diamonds$clarity,
                           levels = c("I1","SI2","SI1","VS2","VS1","VVS2","VVS1","IF"))

# make data frame of just the numerical variables
diamonds_num <- subset(diamonds, select = c(carat,depth,table,price,x,y,z))

# display first rows to check
diamonds_num[1:4,]

# display summary data
summary(diamonds_num)
```

#### Summary function diamonds

```{r, echo=FALSE}
# use the summary function to create the summary data for the numerical variables
MySummary <- function(x){
  return(c(
    length(x),
    min(x),
    quantile(x, .25),
    median(x),
    mean(x),
    quantile(x, .75),
    max(x),
    IQR(x),
    sd(x), 
    skewness(x),
    kurtosis(x)))
}

```

#### Change array rownames

```{r, echo=FALSE}
# store the summary data in a variable and modify row names for the output table
summ_diamonds <- apply(diamonds_num, MySummary, MARGIN=2)

rownames(summ_diamonds) <- c("sample size","minimum",
                                   "first quartile","median",
                                   "mean","third quartile",
                                   "maximum","IQR", "standard deviation",
                            "skewness","kurtosis")
```

### Summary table diamonds

```{r summtablediam}
# produce summary table
knitr::kable(summ_diamonds,
             digits = 3,
             caption = "Summary statistics for 'diamonds' (3 s.f.)")
```

Table \@ref(tab:summtablediam) presents the summary statistics for the numerical variables in the diamonds dataset. 

### Means vector

```{r, echo=FALSE}
means_vec_diam <- matrix(colMeans(diamonds_num), 
                    nrow = length(colnames))
signif(means_vec_diam,4)

```

The estimates for the means vector are displayed in both the output above and in vector form below:

$$
{\bf \hat\mu}=\begin{pmatrix}
0.7979\\
61.75\\
57.46\\
3933\\
5.731\\
5.735\\
3.539
\end{pmatrix}
$$

## Multivariate Tests

Our categorical variables of cut, clarity and color are all ordinal:  

-   cut: a measure of quality (categorical: Fair, Good, Very Good, Premium)\  

-   color: a measure of colour quality (categorical: J, which is poorest quality, to D, which is best)  

-   clarity: a measure of clearness (categorical: from worst to best = I1, SI2, VS2, VS1, VVS2, IF)

Using a Hotelling's T-test we will test the equality of mean vectors of the lowest and highest level of each categorical variable. We might expect the diamonds with lower quality cut, color and clarity to differ significantly from diamonds with high quality cut, colour and clarity. 


```{r}
(hotelling.test(subset(diamonds, cut == "Fair")[,-(2:4)], subset(diamonds, cut == "Premium")[,-(2:4)]))

```

The output above comparing the mean vectors of the 'Fair' and 'Premium' levels of the 'cut' variable gives a test statistic of 6349.2 (which is huge) and a p-value of 0. We therefore reject the null hypothesis that the mean vectors of these two samples are equal.

```{r}
(hotelling.test(subset(diamonds, color == "J")[,-(2:4)], subset(diamonds, color == "D")[,-(2:4)]))

```

The output above comparing the mean vectors of the 'J' (poorest quality) and 'D' (best quality) levels of the 'color' variable gives a test statistic of 5602.4 and a p-value of 0. We therefore reject the null hypothesis that the mean vectors of these two levels are equal.


```{r}
(hotelling.test(subset(diamonds, clarity == "I1")[,-(2:4)], subset(diamonds, clarity == "IF")[,-(2:4)]))

```

The output above comparing the mean vectors of the 'I1' (poorest quality) and 'IF' (best quality) levels of the 'color' variable gives a test statistic of 9242.3 and a p-value of 0. We therefore reject the null hypothesis that the mean vectors of these two levels are equal.

Summary:  

It is no surprise to find that the best and worst categories of cut, color and clarity differ significantly from each other.


## Normality

In our previous EDA we saw that a number of our numeric variables may not follow a normal distribution. We saw this in the Cullen and Frey Plots and also in our summary table by examining the values for kurtosis and skewness. We will create a Normal QQ plot for each numeric variable as well as performing a Kolmogrov-Smirnov goodness of fit test for each numeric variable. The density function of each numeric variable indicate strong deviations from the normal distribution. 


```{r denplots, fig.cap= "Density of Numeric variables", fig.pos= "center", fig.pos= "H"}
a <- ggplot(diamonds, aes(x=carat))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Carat")

b <- ggplot(diamonds, aes(x=depth))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Depth")

c <- ggplot(diamonds, aes(x=table))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Table")

d <- ggplot(diamonds, aes(x=price))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Price")

e <- ggplot(diamonds, aes(x=x))+
  geom_density(color="darkblue", fill="lightblue") + xlab("x")

f <- ggplot(diamonds, aes(x=y))+
  geom_density(color="darkblue", fill="lightblue") + xlab("y")

g <- ggplot(diamonds, aes(x=z))+
  geom_density(color="darkblue", fill="lightblue") + xlab("z")


ggarrange(a, b, c, d, e, f, g + rremove("x.text"), 
          labels = c("Carat", "Depth", "Table", "Price", "x", "y", "z"),
          ncol = 2, nrow = 4)
```     

Figure \@ref(fig:denplots) displays the density plots for the seven numerical variables. Most look like they follow a distribution that is not classically Normal. 

'Carat' has a series of modes (four or five) which suggest a categorical variable that is also influencing the shape. This is also true of 'table' and 'x', and also possibly 'y' and 'z', although the horizontal compression of the data makes it harder to distinguish individual modes. 'Depth' is the one that most resembles a classic Bell curve. The left hand side of 'price' resembles a Normal density, but then has an extremely long right tail, which is apparently characteristic of some types of monetary data. Note also that the lowest value of 'price' is not zero; this makes sense, as no diamond, no matter how small, would be sold for zero dollars. 
Attempting a log transform of numeric variables to increase normality did not yield much success.

```{r denplots2, fig.cap= "Density of Numeric variables", fig.pos= "center", fig.pos= "H"}
a <- ggplot(diamonds, aes(x=log(carat)))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Carat")

b <- ggplot(diamonds, aes(x=log(depth)))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Depth")

c <- ggplot(diamonds, aes(x=log(table)))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Table")

d <- ggplot(diamonds, aes(x=log(price)))+
  geom_density(color="darkblue", fill="lightblue") + xlab("Price")

e <- ggplot(diamonds, aes(x=log(x)))+
  geom_density(color="darkblue", fill="lightblue") + xlab("x")

f <- ggplot(diamonds, aes(x=log(y)))+
  geom_density(color="darkblue", fill="lightblue") + xlab("y")

g <- ggplot(diamonds, aes(x=log(z)))+
  geom_density(color="darkblue", fill="lightblue") + xlab("z")


ggarrange(a, b, c, d, e, f, g + rremove("x.text"), 
          labels = c("Carat", "Depth", "Table", "Price", "x", "y", "z"),
          ncol = 2, nrow = 4)
```     

Figure \@ref(fig:denplots2) shows the density plots of the log transformed data. While the data has clearly been stretched, the shapes of the densities remains similar to the original data. 

## Q-Q plots

The Normal Q-Q plots below show that most of the variables have deviations from Normality.   

### Carat

```{r qqcarat,  fig.pos= "center", fig.pos= "H", fig.cap="Carat"}
qqnorm(diamonds$carat, xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(diamonds$carat, col = "blue", lwd =2)
```

```{r}
ks.test(diamonds$carat, "pnorm", mean=mean(diamonds$carat), sd=sd(diamonds$carat))
```

The QQ plot shows strong deviations from the normal distribution particularly at the tails and this is confirmed in our hypothesis test of normality.

```{r qqcaratlt,  fig.pos= "center", fig.pos= "H", fig.cap="Carat log transformed"}
qqnorm(log(diamonds$carat), xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(log(diamonds$carat), col = "blue", lwd =2)
```

Even with the log transformation, the carat values do not fit the predicted line particularly well (figure \@ref(fig:qqcaratlt)), suggesting that the data is not Normally distributed. 

### Depth

```{r qqdepth,  fig.pos= "center", fig.pos= "H", fig.cap="Depth"}
qqnorm(diamonds$depth, xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(diamonds$depth, col = "blue", lwd =2)
```

```{r}
ks.test(diamonds$depth, "pnorm", mean=mean(diamonds$depth), sd=sd(diamonds$depth))
```

Again the QQplot for depth (figure \@ref(fig:qqcaratlt)) shows substantial deviations from the Normal distribution at the tails. The Kolmogorov-Smirnov test returned a p-value of < 2.2e-16 (machine precision zero). Therefore, we reject the null hypothesis that the data is normally distributed. 

### Table

```{r qqtable,  fig.pos= "center", fig.pos= "H", fig.cap="Table"}
qqnorm(diamonds$table, xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(diamonds$table, col = "blue", lwd =2)
```

```{r}
ks.test(diamonds$table, "pnorm", mean=mean(diamonds$table), sd=sd(diamonds$table))
```

Figure \@ref(fig:qqtable) of the 'table' variable also suggests deviations from Normality with the upper tail in particular sweeping upward away from the predicted line. The Kolmogorov-Smirnov test returned a p-value of < 2.2e-16, confirming that the data does not follow a Normal distribution. 

### Price

```{r qqprice,  fig.pos= "center", fig.pos= "H", fig.cap="Price"}
qqnorm(diamonds$price, xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(diamonds$price, col = "blue", lwd =2)
```

```{r}
ks.test(diamonds$price, "pnorm", mean=mean(diamonds$price), sd=sd(diamonds$price))
```

Figure \@ref(fig:qqprice) shows an unusually shaped red curve, which strongly suggests a distribution other than the Normal. Again, the Kolmogorov-Smirnov test returned a p-value of < 2.2e-16.

### x (length)

```{r qqx,  fig.pos= "center", fig.pos= "H", fig.cap="X"}
qqnorm(diamonds$x, xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(diamonds$x, col = "blue", lwd =2)
```

```{r}
ks.test(diamonds$x, "pnorm", mean=mean(diamonds$x), sd=sd(diamonds$x))
```

### y (width)

```{r qqy,  fig.pos= "center", fig.pos= "H", fig.cap="Y"}
qqnorm(diamonds$y, xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(diamonds$y, col = "blue", lwd =2)
```

```{r}
ks.test(diamonds$y, "pnorm", mean=mean(diamonds$y), sd=sd(diamonds$y))
```

Figure \@ref(fig:qqy) shows that the observed values for the 'y' variable actually fit the predicted line quite well, with the exception of two extreme values at the upper end (right hand side). 

### z (depth)

```{r qqz,  fig.pos= "center", fig.pos= "H", fig.cap="Z"}
qqnorm(diamonds$depth, xlab = "Observations", ylab = "Normal Quantiles", col = "red")
qqline(diamonds$depth, col = "blue", lwd =2)
```

```{r}
ks.test(diamonds$depth, "pnorm", mean=mean(diamonds$depth), sd=sd(diamonds$depth))
```

Figures \@ref(fig:qqx) (variable 'X') and \@ref(fig:qqz) (variable 'Y') both show deviations from Normality.


All of our numerical variables, except perhaps y (width), show obvious deviation from the normal distribution in the QQ plots. The KS goodness of fit test finds evidence that these varaibles do not follow a normal distribution. This is perhaps due to the interaction of different factors from our categorical variables. As we have many levels in our categorical variables we have many factors. See the table below of how many observations were recorded for each factor level.

```{r}
table(interaction(diamonds$cut, diamonds$color, diamonds$clarity))
```

## Melted version of dataset

```{r, echo=FALSE}
# create melted version of the dataset to allow easy graphical manipulation
diamonds_melt <- melt(data = diamonds, id.vars = c("cut","color","clarity"),
                      variable.name = "metrics")

```

## Boxplots and table of 'cut'

**Table: cut count**

\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 Cut & Count \\ 
  \hline
Fair & 1610\\
Good & 4960\\
Ideal & 21551\\
Premium & 13791\\
Very Good & 12082\\
   \hline
\end{tabular}
\end{table}

The table above gives a breakdown of the how many diamonds are in each level of the 'cut' variable. We can see that most are in the 'Ideal', with a substancial number also in the 'Premium' and 'Very Good'. 

```{r bxpt1, fig.cap="Boxplots of 'cut' vs all the numeric variables", echo=FALSE}
ggplot(data=diamonds_melt, aes(x=metrics, y=value)) +
  
  geom_boxplot(aes(col=metrics), notch = TRUE) +
  facet_grid(~ cut) +
  theme(axis.text.x = element_text(size=7, angle=90, hjust=1),
        legend.position = "none")

```

Figure \@ref(fig:bxpt1) shows that all the variables except 'price' are too compressed to view. Therefore, a log transform was performed and the graph redone.

## Boxplots of 'cut' in log scale
The summary of the dataset shows that there are no negative or zero values, so we can proceed with a log transform. 

```{r bxpt1log, fig.cap="Boxplots of 'cut' vs all the numeric variables (log transformed)", echo=FALSE}
ggplot(data=diamonds_melt, aes(x=metrics, y=value)) +
  
  geom_boxplot(aes(col=metrics), notch = TRUE) +
  scale_y_log10()+
  facet_grid(~ cut) +
  theme(axis.text.x = element_text(size=7, angle=90, hjust=1),
        legend.position = "none")

```

The log transform in Figure \@ref(fig:bxpt1log) gives a much better idea of the data. 'Price' (green boxes) is consistent across the different levels of 'cut'. Indeed, on this graph the medians and variances of all the variables look similar across the different levels of 'cut'. However, genuine differences might be difficult to perceive due to the scale of the graph and because the sample size is so large, meaning that a seemingly small difference on the graph could still be significant. Most of the confidence interval notches on the boxplots are too compressed to be of help. Below we conduct an ANOVA to determine if we have evidence of differences in price for different levels of the categorical variable cut.

For two of the variables (measurements 'y', purple, and 'z' pink) in the 'Very Good', 'Premium' and 'Ideal' levels of 'cut' there appear to be some very prominent outliers, as evidenced by the pink and purple dots above and below the boxplots. The variable 'y' is a measure of width in millimeters (mm), while 'z' is a measure of depth in mm. 

## Differences in Price for different levels of Cut

```{r cutlevels, echo = FALSE}
ggplot(subset(diamonds, cut == "Ideal"| cut == "Premium"| cut =="Good"| cut == "Very Good"| cut == "Fair"), aes(x = price, col = cut, group = cut, fill = cut)) +
  geom_density(aes(y = ..density..), alpha = .7)
```

Figure \@ref(fig:cutlevels) shows the density plots for the different levels of the 'price' variable. The legend on the right shows the level names and their order ('fair' = poorest, 'ideal' = best). Of note is the fact that the two best leves (premium and ideal) have significant peaks near the lower end of the price range compared with the other three. This is somewhat surprising, as intuitively one would imagine price to increase as the quality of cut increases. Perhaps it is easier to complete a premium or ideal cut on a smaller diamond, which would then be sold at a cheaper price than a rougher cut on a larger diamond? 

We will now test whether there are significant differences in mean price for different levels of "cut".  


```{r}
cutanova <- aov(price ~ cut, data = diamonds)
summary(cutanova)
```

The ANOVA results above return a p-value of < 2.2e-16, meaning that there is strong evidence to suggest that mean price differs across levels of "cut". 

We will now perform a Tukey Test to determine which pairwise differences are significant

```{r}
TukeyHSD(cutanova, conf.level = 0.95)
```

At the 5% significance level, the only pairs between which we do not see a significant difference in mean price are "very Good" and "Good" as well as "Premium" and "Fair" (output above). 

From the graph of the distributions of price for different levels of cut we can see that not all of them have a shape consistent with being normally distributed. A one Way ANOVA is reasonably robust to departures from normality, particularly as we have a very large sample. We will also perform Levene's test to test the assumption of equal variances and then, if significant, a non-parametric Kruskal Wallis test to determine if there are significant differences in median price for different levels of cut. Again, a one way ANOVA is reasonably robust to departures from equal variance if the sample sizes are the same.

```{r}
leveneTest(price ~ cut, data= diamonds)
kruskal.test(price ~ cut, data = diamonds)
```

Both tests return significant results (output above) indicating that: a) the assumption of equal variance is violated and; b) that we have evidence of a significant difference in median prices for different levels of cut. 

## Boxplots of 'color' in log scale

### Table of 'color' count

**Table: color count**

\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 Color & Count \\ 
  \hline
D & 6775\\
E & 9797\\
F & 9542\\
G & 11292\\
H & 8304\\
I & 5422\\
J & 2808\\
   \hline
\end{tabular}
\end{table}

The table above shows the number of diamonds in each level of the 'color' variable. 

As with the 'cut' variable, we redo the boxplots using the log transform on the data. Figure \@ref(fig:bxpt2log) shows the log transformed version of the boxplots for the 'color' variable.

```{r bxpt2log, fig.cap="Boxplots of 'color' vs all the numeric variables (log transformed)", echo=FALSE}
ggplot(data=diamonds_melt, aes(x=metrics, y=value)) +
  
  geom_boxplot(aes(col=metrics), notch = TRUE) +
  scale_y_log10()+
  facet_grid(~ cut) +
  theme(axis.text.x = element_text(size=7, angle=90, hjust=1),
        legend.position = "none")

```

## Differences in Price for different colors

```{r densitycol, echo = FALSE, fig.cap="Densities of 'price' for the different levels of 'color'"}
ggplot(subset(diamonds, color == "J"| color == "H"| color =="I"| color == "G"| color == "F"| color == "E"| color == "D"), aes(x = price, col = color, group = color, fill = color)) +
  geom_density(aes(y = ..density..), alpha = .7)
```

Figure \@ref(fig:densitycol) shows the density plots of 'price' for the different levels of the 'color' variable. There is a prominent peak on the left for the better quality levels of color (D in pink, E in purple, and F in blue), but otherwise the densities appear to be fairly similar. 


We will now test whether there are significant differences in mean price for different diamond colours. While we see potential evidence that the ANOVA assumptions of normality and equal variance may be violated, ANOVA is reasonably robust to these violations if the sample size is big enough. 

```{r}
coloranova <- aov(price ~ color, data = diamonds)
summary(cutanova)
```
We have strong evidence to suggest that mean price differs across levels of "color". We will now perform a Tukey Test to determine which pairwise comparisons are significant

```{r}
TukeyHSD(coloranova, conf.level = 0.95)
```

The output above shows significant differences in mean price for nearly all pairwise comparisons of diamond colors.

We will also perform a Levene's test to test the assumption of equal variances and then, if significant, a non-parametric Kruskal Wallis test to determine if there are significant differences in median price for different levels of cut.

```{r}
leveneTest(price ~ color, data= diamonds)
kruskal.test(price ~ color, data = diamonds)
```

The output above shows a p-value of < 2.2e-16, meaning that there is strong evidence of a significant difference in the median price for different colour diamonds. 


## Boxplots and table of count of 'clarity'

**Table: clarity count**

\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 Clarity & Count \\ 
  \hline
I1	&741\\
IF	&1790\\
SI1&	13065\\
SI2	&9194\\
VS1	&8171\\
VS2	&12258\\
VVS1&	3655\\
VVS2&	5066\\
   \hline
\end{tabular}
\end{table}

The table above shows the counts for the different levels of the 'clarity' variable. 

For the 'clarity' variable a log transform on the data has been performed for the boxplots. 

```{r bxpt3log, fig.cap="Boxplots of 'clarity' vs all the numeric variables (log transformed)", echo=FALSE}
ggplot(data=diamonds_melt, aes(x=metrics, y=value)) +
  
  geom_boxplot(aes(col=metrics), notch = TRUE) +
  scale_y_log10()+
  facet_grid(~ clarity) +
  theme(axis.text.x = element_text(size=7, angle=90, hjust=1),
        legend.position = "none")

```

Figure \@ref(fig:bxpt3log) shows the boxplots for the log transformed data across the different 'clarity' metrics. Much like the previous two graphs, medians and ranges look relatively constant across the variables. 

## Differences in price for different levels of clarity

```{r claritydensity, echo = FALSE}
ggplot(subset(diamonds, clarity == "I1"| clarity =="SI2"|clarity =="SI1"|clarity =="VS2"| clarity =="VS1"| clarity =="VVS2"| clarity =="VVS1"| clarity =="IF"), aes(x = price, col = clarity, group = clarity, fill = clarity)) +
  geom_density(aes(y = ..density..), alpha = .7)
```

Figure \@ref(fig:claritydensity) shows the densities of the different levels of 'clarity' for price. A prominent peak is visible near the left for the better quality levels (IF, best, pink; WS1 second best, purple; WS2, third best, blue).  

We will now test whether there are significant differences in mean price for different diamond colours. While we see potential evidence that the ANOVA assumptions of normality and equal variance may be violated, ANOVA is reasonably robust to these violations if the sample size is big enough. 

```{r}
clarityanova <- aov(price ~ clarity, data = diamonds)
summary(clarityanova)
```
The output above returns a p-value of < 2.2e-16, meaning there is strong evidence to suggest that mean price differs across levels of "clarity". We will now perform a Tukey Test to determine which pairwise comparisons are significant

```{r}
TukeyHSD(clarityanova, conf.level = 0.95)

```

The output of the Tukey test is above. Most pairwise combinations show a significant difference. There are only six that do not show a difference and they are: SI1-I1; VS2-I1; VS1-I1; VS2-SI1; VS1-VS2; and IF-VVS1. 

We will also perform a Levene's test to test the assumption of equal variances and then, if significant, a non-parametric Kruskal Wallis test to determine if there are significant differences in median price for different levels of cut.

```{r}
leveneTest(price ~ clarity, data= diamonds)
kruskal.test(price ~ clarity, data = diamonds)
```

The output of the two tests above show that there is not equal variances between the levels, and that there is a significant difference between different levels of clarity.

### The covariance matrix

```{r tabcovdia, echo=FALSE}
covar_diam <- cov(diamonds_num)
knitr::kable(signif(covar_diam,2), caption = "Covariance matrix for 'diamonds' (2 s.f.)")
```

The covariance matrix can be seen in table \@ref(tab:tabcovdia). 

### The correlation matrix

```{r tabcorrdiam, echo=FALSE}
correl_diam <- cor(diamonds_num)


knitr::kable(signif(correl_diam,2), caption = "Correlation matrix for 'diamonds' (2 s.f.)")
```

The correlation matrix can be seen in table \@ref(tab:tabcorrdiam).

## Visualisation of the correlation matrix

```{r correldiam, fig.cap="The pairs plot for diamonds", echo=FALSE}

ggcorrplot(cor(diamonds_num),
           method = "circle",
           hc.order = TRUE,
           type = "lower")
    
```

Figure \@ref(fig:correldiam) shows the correlation plot for the numerical variables in the diamonds data. 'Carat', 'x', 'y', 'z' and 'price' all show very strong correlations with each other, as evidenced by the large red dots. As "x", "y" and "z" are all measures of size we should expect this and there may be some redundancy in these predictors.  The 'table' variable is relatively uncorrelated with any of the others. 'Depth' and 'table' are negatively correlated (large purple dot), while depth is not correlated with any other variable. The strongest predictor of price is carat with length, width, depth also strongly correlated with price. Table is only very weakly correlated with price while depth is negatively correlated with price.


```{r pairsplot2, fig.cap="The pairs plot for Diamonds numeric values", fig.pos="center", echo=FALSE}
#the pairs plot
pairs.panels(diamonds_num, method = "spearman", 
              #hist.col = "lightgreen", 
              density = TRUE, 
              ellipses = FALSE)
```

Figure \@ref(fig:pairsplot2) shows the pairs plot for the numeric variables. While the scatterplots are small, it is clear that a number of pairs show little to no correlation, supporting the results from the correlation plot (figure \@ref(fig:correldiam)). 

## Scatterplots

Based on the outcome of the correlation pairs plot (figure  \@ref(fig:correldiam)) we have chosen the pairs 'depth' and 'table', and 'price' and 'carat' to produce scatter plots of, because one pair shows a strong positive correlation while the other shows a strong negative correlation.


```{r scatdiamdt, fig.cap="Scatterplot with marginal boxplots of 'depth' vs 'table'", echo=FALSE}
diam_deptab <- ggplot(diamonds, aes(x=depth, y=table))+
  geom_point()+
  coord_fixed()+
 
  labs(title = "Scatterplot with \nmarginal boxplots")
  
ggMarginal(diam_deptab, type = "boxplot", notch=TRUE, size = 15, 
           fill="grey")
```

Figure \@ref(fig:scatdiamdt) shows the scatterplot with marginal boxplots of the 'depth' and 'table' variables. Because of the large number of observations, some of the visualisation is compressed to the point where it is difficult to read, for example the outliers on the marginal boxplot along the top. In the above example, the effects ratio is fixed to allow easier visualisation of the negative correlation, but this has resulted in a horizontal compression.

We can see from the marginal boxplots (grey boxes along the top and right) that most of the datapoints are clustered tightly around the medians of both variables, causing an area in the middle of the scatterplot that is so dense at to be black. There are a few outliers for each variable, but not many considering that there are over 53,000 observations. The strong negative correlation that we saw in the pairs plot is reasonably visible as evidenced by the dark directional band going from top left toward the bottom right.


```{r scatdiamcp, fig.cap="Scatterplot with marginal boxplots of 'carat' vs 'price'", echo=FALSE}
diam_deptab <- ggplot(diamonds, aes(x=carat, y=price))+
  geom_point()+
  
 
  labs(title = "Scatterplot with marginal boxplots of 'carat' vs 'price'")
  
ggMarginal(diam_deptab, type = "boxplot", notch=TRUE, size = 15, 
           fill="grey")
```

Figure \@ref(fig:scatdiamcp) shows the scatterplot with marginal boxplots of the 'carat' and 'price' variables. The expected positive correlation is clearly visible as a dark band running from the bottom left steeply towards the top right. There are vertical bands of visible at the $1, 1.5~and~2$ values of carat. This is a curious finding and one that is an obvious point of investigation for a more comprehensive analysis. Perhaps jewelers are in the habit of rounding down to the nearest whole or half number, despite carat being a continuous variable? Another curious aspect is why the lower parts of those ranges (from 1.5 to 1.6, for example) are so densly packed with observations, while the upper parts (1.8 to 2) appear virtually empty. It seems very unlikely that by chance there were few stones of this weight, so presumably another factor is at play.


```{r scatdiamxz, fig.cap="Scatterplot with marginal boxplots of 'x' vs 'z'", echo=FALSE}
diam_deptab <- ggplot(diamonds, aes(x= diamonds$x, y= diamonds$z))+
  geom_point()+
  
  labs(title = "Scatterplot with marginal boxplots of 'X' vs 'Y'", 
       x="X", y="Y")
  
ggMarginal(diam_deptab, type = "boxplot", notch=TRUE, size = 15, 
           fill="grey")
```
Figure \@ref(fig:scatdiamxz) illustrates the strong positve correlation between the measurement dimensions of length and depth (x and z). The Correlation plot shows strong positive correlations between x (length in mm), y (width in mm) and z (depth in mm) indicating that there may be some redundancy between these variables. Of note are two extreme outliers: one in the middle at the top and the other at (0,0). The latter suggests a data entry error or a failure to measure that particular variable, as it makes no sense to include a diamond with zero width and zero depth. The outlier at the middle top could also be an error, as it does not make sense that one diamond would have a width (Y variable) three to four times the next widest, but a depth (X variable) that is quite small. The output of the code below shows that both the 'X' and 'Y' variables have eight and seven zero values respectively, while the 'Z' variable has twenty.

The code below also shows that there are two extreme upper values for 'Y', both of which are so far above normal that it is likely they are errors of some sort. There is also a suspiciously high value for 'z'. 


```{r}
# count the number of zero values for x, y and z
sum(diamonds$x==0)
sum(diamonds$y==0)
sum(diamonds$z==0)

# display the ten largest values for x, y and z

sort(diamonds$x, decreasing = T)[1:5]
sort(diamonds$y, decreasing = T)[1:5]
sort(diamonds$z, decreasing = T)[1:5]

```

```{r}
diamonds_num[1:4,]
```


## Mahalanobis Distance

We will examine and display surprising points in our dataset using the Mahalanobis Distance.

```{r}
diamonds_num$price <- as.numeric(diamonds_num$price)
mu.hat <- colMeans(diamonds_num)
sigma.hat <- cov(diamonds_num)
dM <- mahalanobis(diamonds_num, center = mu.hat, cov = sigma.hat)
upper.quantiles <- qchisq(c(.9,.95,.99), df = 7)
density.at.quantiles <- dchisq(x = upper.quantiles, df = 7)
cut.points <- data.frame(upper.quantiles, density.at.quantiles)
```

```{r}
diamonds_num$dM <- dM
diamonds_num$surprise <- cut(diamonds_num$dM, breaks = c(0, upper.quantiles, Inf), labels = c("Typical", "Somewhat", "Surprising", "very"))
table(diamonds_num$surprise)
```

We see from the output above that while the vast majority of diamonds are typical there are a reasonable amount of "Surprising" and "Very Surprising" points in this dataset. In terms of the 'very surprising' distances, we would expect 1% of the data to be this distant. However, 3.4% of values lie this distant (code below). This suggests that these values do not belong to the same distribution as the rest of the data. 

```{r}
1839/length(diamonds$carat)
```

We can see how many very surprising points (as identified with the Mahalanobis Distance) are members of each level of our categorical variables. This might help to indicate if any classes contain more surprising points than others.

```{r}
diamonds$surprise <- diamonds_num$surprise <- cut(diamonds_num$dM, breaks = c(0, upper.quantiles, Inf), labels = c("Typical", "Somewhat", "Surprising", "very"))

VSdiamonds <- subset(diamonds, surprise =="very")
table(interaction(VSdiamonds$cut))
table(interaction(VSdiamonds$clarity))
table(interaction(VSdiamonds$color))
```


## Linear regression model and model equation

We have created a linear regression model with model equation:

$y = \alpha + \beta carat + \gamma cut + \tau color + \omega clarity + \epsilon$

```{r}
lm.milestone4 <- lm(y~carat+cut+color+clarity, data = diamonds, x = T)
summary(lm.milestone4)
#pchisq(lm.milestone4$, df=lm.milestone4$, lower.tail=FALSE)
```

The output above from the linear regression model shows that most of the variables appear to be useful in predicting price (based on their p-values) except for clarityVVS1 and ClarityIF.  

# References

