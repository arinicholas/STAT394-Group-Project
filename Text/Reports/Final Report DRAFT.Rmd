---
title: "STAT394 Group Project Final Report"
author: "Ken MacIver, Tom Tribe, Jundi Yang, Mei Huang"
date: "`r Sys.Date()`"
classoption: 12pt
output: bookdown::pdf_document2
bibliography: ./Bibliography/MASTER.bib
header-includes: \usepackage{float}
                    \floatplacement{figure}{H}
                    \floatplacement{table}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
require(ggthemes)
library(ggstance)
library(ggcorrplot)
library(ggplot2)
library(mvtnorm)
library(fitdistrplus)
library(GGally)
library(ggExtra)
library(reshape2)
library(xtable)
library(moments)
library(psych)
library(Hotelling)
library(car)
library(HDtest)
library(ggpubr)
library(cowplot)
library(devtools)
library(ggbiplot)
library(factoextra)
library(devtools) # general package
library(ggord)
library(klaR)
library(cluster) # for silhouette plot

options(xtable.floating = FALSE)
options(xtable.timestamp = "")
```


# Introduction  

Our multivariate statistical investigation uses the 'Diamonds' data set. This data set is a base data set in R (available in the ggplot2 package) and is also freely available on Kaggle [@diamondskaggle]. It contains information on ten different variables for 53940 diamonds. Of these ten variables three are categorical while 7 are numerical. 

## The variables

- Carat: a measure of the diamond's weight. One carat equals 1/5 gram. In this data set there are diamonds with carat values ranging from 0.2 - 5.01.  

- Cut: A diamond's cut defines its proportions and its ability to reflect light. This variable has five levels: Fair (lowest quality), Good, Very Good, Premium and Ideal (highest quality).  

- Color: A diamond's color refers to how clear/colorless it is. This variable has seven levels: J (lowest quality), I, H, G, F, E, D (highest quality).

- Clarity: measures small imperfections on the surface and within the stone. This variable has eight levels:  I1 (lowest clarity), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (highest clarity).  

- x: length in mm. In this data set there are diamonds with a length ranging from 0 - 10.74. 

- y: width in mm. In this data set there are diamonds with a width ranging from 0 - 58.9.  

- z: depth in mm. In this data set there are diamonds with a depth ranging from 0 - 31.8. 

- Depth: total depth percentage. This is calculated by dividing the total width by the total depth ($depth=\frac{2\times z}{(x+y)}$). Depth percentage impacts how light reflects of the diamond. In this data set we have diamonds with a depth percentage ranging from 43% - 79%.

- Table: The flat facet on the top of a diamond is called its table. Table is calculated by dividing table width by the total width. Table percentage impacts how light reflects of the diamond. In this data set there are diamonds with a table percentage ranging from 43% - 95%.

- Price: price of the diamond in United States dollars (USD). In this data set there are diamonds with a price ranging from $326 - $18823.

### Why 'diamonds'?

We selected the diamonds dataset because it was easy to understand what the variables were measuring. This was in contrast to some of the other ones we looked at which required domain specific familiarity, such as knowledge about biology or chemistry (or even worse, bio-chemistry!). This data set also allows us to undertake an investigation from which we glean insights about diamonds that have real-world application and use. 

### Aims

Our primary aim was to identify which variables best predictor the price of any given diamond. We hypothesised that increased diamond size (x, y and z) and weight will be positively correlated with diamond price. We also expected to see increased prices for diamonds with higher levels of the categorical variables. We were unsure how diamond depth and table percentage will relate to diamond price. 

We also sought to explore the techniques of Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA) and Cluster Analysis (CA) that we have learned in STAT394. The diamonds dataset has 280 unique possible interactions (5 x 7 x 8) between different levels of the categorical variables. Our secondary aim was to discover whether one of these techinques (PCA, LDA or CA) could classify the data in a simpler manner.

# Methodology

The diamonds data set was accessed via the kaggle.com website [@diamondskaggle] while all statistical analysis and reporting was completed using the computer software package R [@R-base], in RStudio [@RStudio] and using RMarkdown [@RMarkdown]. Github [@github] was used a repository for storing all relevant documents and code during this project.

Upon loading the data set into R we first used the following code to delete unnecessary columns, ensure categorical variables were treated as factors with set levels and created a subset data set containing only the numeric variables.

```{r}
# Read the data set into R
diamonds <- read.csv("./diamonds.csv", encoding = "UTF-8")
# Remove the index column
diamonds$X <- NULL
# Set categorical variables as factors and set levels
diamonds$cut <- factor(diamonds$cut, 
                       levels = c("Fair","Good","Very Good","Premium","Ideal"))
diamonds$color <- factor(diamonds$color, 
                         levels = c("J","I","H","G","F","E","D"))
diamonds$clarity <- factor(diamonds$clarity,
                  levels = c("I1","SI2","SI1","VS2","VS1","VVS2","VVS1","IF"))
# Make data frame of just the numerical variables
diamonds_num <- subset(diamonds, select = c(carat,depth,table,price,x,y,z))
```

When scaling numerical values in our data set we used the `scale()` function.  

When taking smaller samples from our data set to improve the interpretability of visual plots we used a seed consisting of either the student identification number of the team member who wrote the code or 1234567890, and the pseudo random number generator Mersenne Twister.

To begin with, we undertook an in-depth Exploratory Data Analysis (EDA) of the data. The key results from the EDA can be found in the results section below. 

# Results

## Consolidated Exploratory Data Analysis (EDA)

In this section we present key findings from the consolidated Exploratory Data Analysis. 

### Summaries of Data


```{r summtab, echo=FALSE}
# use the summary function to create the summary data for the numerical variables
MySummary <- function(x){
  return(c(
    length(x),
    min(x),
    quantile(x, .25),
    median(x),
    mean(x),
    quantile(x, .75),
    max(x),
    IQR(x),
    sd(x), 
    skewness(x),
    kurtosis(x)))
}


summ_diamonds <- apply(diamonds_num, MySummary, MARGIN=2)

rownames(summ_diamonds) <- c("sample size","minimum",
                                   "first quartile","median",
                                   "mean","third quartile",
                                   "maximum","IQR", "standard deviation",
                            "skewness","kurtosis")

knitr::kable(summ_diamonds,
             digits = 2,
             caption = "Summary statistics for 'diamonds' (2 d.p.)")
```

A brief look at the summary statistics of the numerical variables (table \@ref(tab:summtab)) shows that they all exist on very different scales. We also see high skewness values for carat, price, y and z and high kurtosis values for all variables particularly y and z. Both of these indicate non-normality of our numeric variables. It is also interesting to note that at least one diamond has a zero value for x, y and z as that is the minimum value for those variables. This will be further investigated in the outliers and unusual points section. 


## Categorical Summaries

**Table: cut count**

\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 Cut & Count \\ 
  \hline
Fair & 1610\\
Good & 4960\\
Ideal & 21551\\
Premium & 13791\\
Very Good & 12082\\
   \hline
\end{tabular}
\end{table}

The table above gives a breakdown of the how many diamonds are in each level of the 'cut' variable. We can see that most are in the 'Ideal', with a substantial number also in the 'Premium' and 'Very Good'. 

### Table of 'color' count

\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 Color & Count \\ 
  \hline
D & 6775\\
E & 9797\\
F & 9542\\
G & 11292\\
H & 8304\\
I & 5422\\
J & 2808\\
   \hline
\end{tabular}
\end{table}

The table above shows the number of diamonds in each level of the 'color' variable.

**Table: clarity count**

\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 Clarity & Count \\ 
  \hline
I1	&741\\
IF	&1790\\
SI1&	13065\\
SI2	&9194\\
VS1	&8171\\
VS2	&12258\\
VVS1&	3655\\
VVS2&	5066\\
   \hline
\end{tabular}
\end{table}

The table above shows the counts for the different levels of the 'clarity' variable.

### Distribution of Numeric Variables 

While examining histograms, Cullen and Frey Plots, skewness and kurtosis of the numerical variables in our EDA we had reason to believe that the numerical variables were not normally distributed. The assumption of normality underlies many statistical procedures so we investigated this in more depth using Normal Quantile plots and goodness of fit tests. 

```{r normal QQ plots, fig.cap= "Normal QQ Plots of Numeric Variables", fig.pos= "center", fig.pos= "H"}
par(mfrow=c(3,3))  
qqnorm(diamonds$carat, xlab = "Observations", ylab = "Normal Quantiles", main = "Carat", col = "red")
qqline(diamonds$carat, col = "blue", lwd =2)
qqnorm(diamonds$depth, xlab = "Observations", ylab = "Normal Quantiles", main = "Depth", col = "red")
qqline(diamonds$depth, col = "blue", lwd =2)
qqnorm(diamonds$table, xlab = "Observations", ylab = "Normal Quantiles", main = "Table", col = "red")
qqline(diamonds$table, col = "blue", lwd =2)
qqnorm(diamonds$price, xlab = "Observations", ylab = "Normal Quantiles", main = "Price", col = "red")
qqline(diamonds$price, col = "blue", lwd =2)
qqnorm(diamonds$x, xlab = "Observations", ylab = "Normal Quantiles", main = "x", col = "red")
qqline(diamonds$x, col = "blue", lwd =2)
qqnorm(diamonds$y, xlab = "Observations", ylab = "Normal Quantiles", main = "y", col = "red")
qqline(diamonds$y, col = "blue", lwd =2)
qqnorm(diamonds$depth, xlab = "Observations", ylab = "Normal Quantiles", main = "z", col = "red")
qqline(diamonds$depth, col = "blue", lwd =2)
```

Despite the small size of the Normal QQ plots shown above it is clear they indicate that each numeric variable deviates significantly from a normal distribution. We tested this using Kolmogorov-Smirnov goodness of fit test. The results from these tests are shown in the table below. 

**Table: Kolmogorov-Smirnov GOF Results**

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 Variable & Test Statistic (D) & p-value \\ 
  \hline
Carat & 0.12274 & < 2.2e-16 \\
Depth & 0.075871 & < 2.2e-16  \\
Table & 0.13225 & < 2.2e-16\\
Price & 0.18467 &  < 2.2e-16 \\
x & 0.093545 & < 2.2e-16 \\
y & 0.088528 & < 2.2e-16 \\
z & 0.089273 & < 2.2e-16 \\
   \hline
\end{tabular}
\end{table}

The table above shows that for each numeric variable the KS goodness of fit test gave evidence that it did not follow a normal distribution 

### Correlation Matrix

```{r corrplot, fig.cap="A Visualization of the Correlation Matrix", echo=FALSE}
ggcorrplot(cor(diamonds_num),
           method = "circle",
           hc.order = TRUE,
           type = "lower")
```


Figure \@ref(fig:corrplot) shows the correlation plot for the numerical variables in the diamonds data. 'Carat', 'x', 'y', 'z' and 'price' all show very strong correlations with each other, as evidenced by the large red dots. As "x", "y" and "z" are all measures of size we should expect this and there may be some redundancy in these predictors.  The 'table' variable is relatively uncorrelated with any of the others. 'Depth' and 'table' are negatively correlated (large purple dot), while depth is not correlated with any other variable. The strongest predictor of price is carat with length, width, depth also strongly correlated with price. Table is only very weakly correlated with price while depth is negatively correlated with price.


### Price differences across Categorical Variables

As our leading question is investigating which variables are most predictive or price we decided to investigate if there are significant differences in price across levels of each categorical variable. 

#### Cut 

```{r, echo = FALSE}
tapply(diamonds$price, diamonds$cut, mean)
```

We see that the mean price of diamonds does differ for different levels of "cut". However, we see that improved cut does not necessarily lead to increased price.

```{r densitycut, echo = FALSE}
ggplot(subset(diamonds, cut == "Ideal"| cut == "Premium"| cut =="Good"| cut == "Very Good"| cut == "Fair"), aes(x = price, col = cut, group = cut, fill = cut)) +
  geom_density(aes(y = ..density..), alpha = .7)
```

Figure \@ref(fig:densityclar)shows the density plots for the different levels of the 'price' variable. The legend on the right shows the level names and their order ('fair' = poorest, 'ideal' = best). Of note is the fact that the two best leves (premium and ideal) have significant peaks near the lower end of the price range compared with the other three. This is somewhat surprising, as intuitively one would imagine price to increase as the quality of cut increases. We conducted a Analysis of Variance to see if these differences in mean price across levels of cut were significant. we also conducted a Levene's test to verfiy if the assumption of homogeneity of variance was violated.  If significant we then implemented a non-parametric Kruskal Wallis Test. From the graph of the distributions of price for different levels of cut we can see that not all of them have a shape consistent with being normally distributed. A one Way ANOVA is reasonably robust to departures from normality, particularly as we have a very large sample. The results are summarised on the table below and the code for theses tests may be found in the appendices. 

**Table: ANOVA of Price by Cut**

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 Test & Test Statistic & p-value \\ 
  \hline
ANOVA & 175.7 & < 2.2e-16 \\
Levene's Test & 123.6 & < 2.2e-16  \\
Kruskal Wallis & 978.62 & < 2.2e-16\\
   \hline
\end{tabular}
\end{table}

The ANOVA results above return a p-value of < 2.2e-16, meaning that there is strong evidence to suggest that mean price differs across levels of "cut". The Tukey Test indicated that at the 5% significance level, the only pairs between which we do not see a significant difference in mean price are "very Good" and "Good" as well as "Premium" and "Fair". Both the Levene's test and Kruskal Wallis Test return significant results  indicating that: a) the assumption of equal variance is violated and; b) that we have evidence of a significant difference in median prices for different levels of cut.  

#### Clarity

```{r, echo = FALSE}
tapply(diamonds$price, diamonds$clarity, mean)
```

Again, we see an indication the the mean price of diamonds does vary across different levels of clarity. Interestingly the diamonds with the two highest clarities show the lowest mean price. 

```{r}
cutplot <- ggplot(subset(diamonds, cut == "Ideal"| cut == "Premium"| cut =="Good"| cut == "Very Good"| cut == "Fair"), aes(x = price, col = cut, group = cut, fill = cut)) +
  geom_density(aes(y = ..density..), alpha = .7)

clarityplot <- ggplot(subset(diamonds, clarity == "I1"| clarity =="SI2"|clarity =="SI1"|clarity =="VS2"| clarity =="VS1"| clarity =="VVS2"| clarity =="VVS1"| clarity =="IF"), aes(x = price, col = clarity, group = clarity, fill = clarity)) +
  geom_density(aes(y = ..density..), alpha = .7)

colorplot <- ggplot(subset(diamonds, color == "J"| color == "H"| color =="I"| color == "G"| color == "F"| color == "E"| color == "D"), aes(x = price, col = color, group = color, fill = color)) +
  geom_density(aes(y = ..density..), alpha = .7)

ggarrange(cutplot, clarityplot, colorplot, ncol =2, nrow =2)
  
```


```{r densityclar, echo = FALSE}
ggplot(subset(diamonds, clarity == "I1"| clarity =="SI2"|clarity =="SI1"|clarity =="VS2"| clarity =="VS1"| clarity =="VVS2"| clarity =="VVS1"| clarity =="IF"), aes(x = price, col = clarity, group = clarity, fill = clarity)) +
  geom_density(aes(y = ..density..), alpha = .7)
```

Figure \@ref(fig:densityclar) shows the densities of the different levels of 'clarity' for price. A prominent peak is visible near the left for the better quality levels (IF, best, pink; WS1 second best, purple; WS2, third best, blue). We conducted a Analysis of Variance to see if these differences in mean price across levels of clarity were significant. While we see potential evidence that the ANOVA assumptions of normality and equal variance may be violated, ANOVA is reasonably robust to these violations if the sample size is big enough.  We also conducted a Levene's test to verfiy if the assumption of homogeneity of variance was violated. If significant we then implemented a non-parametric Kruskal Wallis Test. The results are summarised on the table below and the code for theses tests may be found in the appendices.

**Table: ANOVA of Price by Clarity**

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 Test & Test Statistic & p-value \\ 
  \hline
ANOVA & 215 & < 2.2e-16 \\
Levene's Test & 77.809 & < 2.2e-16  \\
Kruskal Wallis & 2718.2 & < 2.2e-16\\
   \hline
\end{tabular}
\end{table}

The output frpm the ANOVA returns a p-value of < 2.2e-16, meaning there is strong evidence to suggest that mean price differs across levels of "clarity". The output of the Levene's test and Kruskal Wallis test above show that there is not equal variances between the levels, and that there is a significant difference between different levels of clarity. A tukey test showed that most pairwise combinations show a significant difference. There are only six that do not show a difference and they are: SI1-I1; VS2-I1; VS1-I1; VS2-SI1; VS1-VS2; and IF-VVS1.

#### Color

```{r, echo = FALSE}
tapply(diamonds$price, diamonds$color, mean)
```

Again, we see an indication the the mean price of diamonds does vary across different levels of color. Interestingly the diamonds with the two highest color quality show the lowest mean price. 

```{r densitycol, echo = FALSE, fig.cap="Densities of 'price' for the different levels of 'color'", echo = FALSE}
ggplot(subset(diamonds, color == "J"| color == "H"| color =="I"| color == "G"| color == "F"| color == "E"| color == "D"), aes(x = price, col = color, group = color, fill = color)) +
  geom_density(aes(y = ..density..), alpha = .7)
```

Figure \@ref(fig:densitycol) shows the density plots of 'price' for the different levels of the 'color' variable. There is a prominent peak on the left for the better quality levels of color (D in pink, E in purple, and F in blue), but otherwise the densities appear to be fairly similar. We will now test whether there are significant differences in mean price for different diamond colours. While we see potential evidence that the ANOVA assumptions of normality and equal variance may be violated, ANOVA is reasonably robust to these violations if the sample size is big enough. We also conducted a Levene's test to verfiy if the assumption of homogeneity of variance was violated. If significant we then implemented a non-parametric Kruskal Wallis Test. The results are summarised on the table below and the code for theses tests may be found in the appendices.

**Table: ANOVA of Price by Clarity**

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 Test & Test Statistic & p-value \\ 
  \hline
ANOVA & 175.7 & < 2.2e-16 \\
Levene's Test & 219.12 & < 2.2e-16  \\
Kruskal Wallis & 1335.6 & < 2.2e-16\\
   \hline
\end{tabular}
\end{table}

We have strong evidence to suggest that mean price differs across levels of "color". The output of the Levene's test and Kruskal Wallis test above show that there is not equal variances between the levels, and that there is a significant difference in median price across different levels of clarity. The output from the Tukey Test showed significant differences in mean price for nearly all pairwise comparisons of diamond colors.


### Outliers and Unusual Points 

#### Mahalanobis Distance

We decided too investigate outliers and unusual points in our dataset. These points may have increased leverage or influence when we come to using variables to predict price. We began by using the Mahalanobis Distance to identify surprising and very surprising points.

```{r, echo = FALSE}
diamonds_num$price <- as.numeric(diamonds_num$price)
mu.hat <- colMeans(diamonds_num)
sigma.hat <- cov(diamonds_num)
dM <- mahalanobis(diamonds_num, center = mu.hat, cov = sigma.hat)
upper.quantiles <- qchisq(c(.9,.95,.99), df = 7)
density.at.quantiles <- dchisq(x = upper.quantiles, df = 7)
cut.points <- data.frame(upper.quantiles, density.at.quantiles)
diamonds_num$dM <- dM
diamonds_num$surprise <- cut(diamonds_num$dM, breaks = c(0, upper.quantiles, Inf), labels = c("Typical", "Somewhat", "Surprising", "very"))
table(diamonds_num$surprise)
```

We see from the output above that while the vast majority of diamonds are typical there are a reasonable amount of "Surprising" and "Very Surprising" points in this dataset. We can see how many very surprising points (as identified with the Mahalanobis Distance) are members of each level of our categorical variables. This might help to indicate if any classes contain more surprising points than others.

```{r, echo = FALSE}
diamonds$surprise <- diamonds_num$surprise <- cut(diamonds_num$dM, breaks = c(0, upper.quantiles, Inf), labels = c("Typical", "Somewhat", "Surprising", "very"))

VSdiamonds <- subset(diamonds, surprise =="very")
table(interaction(VSdiamonds$cut))
table(interaction(VSdiamonds$clarity))
table(interaction(VSdiamonds$color))
```

#### Zero Values 

In this section we identify any zero values and determine whether or not they are errors.

```{r, echo = FALSE}
sort(decreasing=F, diamonds$carat)[1:10]
sort(decreasing=F, diamonds$x)[1:10]
sort(decreasing=F, diamonds$y)[1:10]
sort(decreasing=F, diamonds$z)[1:22]
sort(decreasing=F, diamonds$depth)[1:10]
sort(decreasing=F, diamonds$table)[1:10]
sort(decreasing=F, diamonds$price)[1:10]
```

The output above shows that x, y and z all have a number of zero values, which presumably are errors.

### Idendifying whether the zero observations are errors

## Make a data.frame version of dataset

```{r}
diamonds.df <- data.frame(diamonds)
diamonds.df[1:4,]

```

```{r}
# display the zero values for 'x'
diamonds.df[diamonds$x==0,]
```


```{r}
# display the zero values for 'y'
diamonds.df[diamonds$y==0,]
```

```{r}
# display the zero values for 'z'
diamonds.df[diamonds$z==0,]
```

The outputs above show that the zero values for 'x', 'y' and 'z' are all errors. We can tell this because these diamonds have carat, depth and price values, meaning that they cannot have zero length (x), width (y) and depth (z). Note that for a lot of the observations with zero values in one of these variables also have zero values in the others. The variable 'y' is a good example; the output shows that every observation with a zero value for 'y' also has zero values for 'x' and 'z'.  

### Upper-value outliers

The outputs below show the upper values for the seven numerical variables. This output guides further investigation as to which are likely to be genuine and which are probably errors. 

```{r}
# show ten largest values for each of the seven numerical variables
sort(decreasing=T, diamonds$carat)[1:10]
sort(decreasing=T, diamonds$x)[1:10]
sort(decreasing=T, diamonds$y)[1:10]
sort(decreasing=T, diamonds$z)[1:10]
sort(decreasing=T, diamonds$depth)[1:10]
sort(decreasing=T, diamonds$table)[1:10]
sort(decreasing=T, diamonds$price)[1:10]
```

The output above shows the ten largest values for each of the seven numerical variables. At a glance (informal inference) it appears that 'carat', 'y', 'z' and 'table' all have one or more values that are considerably higher than the rest, with y and z having maximums that are so extreme it is worth considering whether they are erroneous.   

## Determining whether the outliers are errors

### The 'x' variable: probably no upper value errors

```{r}
# display the values of 'x' that are greater than or equal to 10
diamonds.df[diamonds$x>=10,]

```

The output above shows that the largest 'x' values are not outrageously larger than the rest. Additionally, the values of the other variables for the largest 'x' value are reasonably aligned in terms of magnitude, suggesting that these large 'x' values are genuine.

### The 'y' variable: probably 2 upper value errors

```{r}
# display the values of 'x' that are greater than or equal to 11
diamonds.df[diamonds$y>=10,]

```

The output above suggests that the two extreme values for 'y' are almost certainly errors. They are 58.90	and 31.80; both are far larger than the next highest value, which is 10.54. It is very unlikely that diamonds with such enormous width values do not also have extreme length and depth values, or that they did not sell for more money. 

### The 'z' variable: probably 2 upper value errors

```{r}
diamonds.df[diamonds$z>=8,]

```

Similarly with the extreme value of 'z' (31.80). The other dimensions of this diamond do not tally with the extreme depth value, nor does the relatively low price. The next highest value has been included for comparison (8.06). This is almost certainly an error.

### The 'carat' variable: probably no upper value errors

```{r}
diamonds.df[diamonds.df$carat>4,]
```

The output above shows that the highest value for 'carat' (5.01) is not outrageously higher than the next highest (4.50), suggesting that this is a genuine value. Also, the other variables are comparible between the highest and second highest, so it is likely that this value can be trusted. 

### The 'table' variable: probably no upper value errors

```{r}
# display the values of 'table' that are greater than or equal to 73
diamonds.df[diamonds.df$table>=73,]
```

The output above for the highest values of 'table' show that the diamond with the largest value (95) was also considerably larger in other ways and was much more expensive. This suggests that this is a genuine value, rather than an error.  

### 'depth' and 'price': probably no upper value errors

```{r}
sort(diamonds.df$depth, decreasing = TRUE)[1:10]
sort(diamonds.df$price, decreasing = TRUE)[1:10]
```

The output above shows that neither 'depth' nor 'price' have any extreme values. We can probably safely conclude that these are all genuine upper values.

## Colour-coded scatterplots

### Scatterplot of 'Carat' vs 'Price', colour-coded by 'Cut'

```{r caratcut, fig.cap="Carat vs Price, coloured by Cut"}

# scatterplot of carat vs price, but also colouring the observations
# by 'cut'
ggplot(data=diamonds, aes(x=carat, y=price, color=cut))+
  geom_point()+
  guides(colour=guide_legend(reverse = T))
```

Figure \@ref(fig:caratcut) shows the scatterplot of 'carat' versus 'price' and coloured by 'cut'.

### Scatterplot of 'Carat' vs 'Price', colour-coded by 'Clarity'

```{r caratclarity, fig.cap="Carat vs Price coloured by Clarity"}

# scatterplot of carat vs price, but also colouring the observations
# by 'cut'
ggplot(data=diamonds, aes(x=carat, y=price, color=clarity))+
  geom_point()+
  guides(colour=guide_legend(reverse = T))
```


Figure \@ref(fig:caratclarity) shows the scatterplot of 'carat' versus 'price' and coloured by 'clarity'. 


### Scatterplot of 'Carat' vs 'Price', colour coded by 'Color'

```{r caratcolor, fig.cap="Carat vs Price coloured by Color"}

# scatterplot of carat vs price, but also colouring the observations
# by 'cut'
ggplot(data=diamonds, aes(x=carat, y=price, color=color))+
  geom_point()+
  guides(colour=guide_legend(reverse = T))
```


Figure \@ref(fig:caratcolor) shows the scatterplot of 'carat' versus 'price' and coloured by 'color'. 

In the three scatterplots figures \@ref(fig:caratcut), \@ref(fig:caratclarity) and \@ref(fig:caratcolor) we see a clear trend of lighter diamonds (lower 'carat' values) that are most expensive (so, in the upper left of the plot) having the highest quality of 'cut', 'clarity' and 'color'. This is no surprise, as we would expect the most expensive lighter diamonds to be of the best quality. 

Conversely, we can also see some heavier diamonds which are of lower quality and lower price. Note in figure \@ref(fig:caratcut) that some of the lowest quality diamonds in terms of 'cut' (orange dots in the centre of the plot, on the vertical value of 2) are relatively cheap, despite being heavier than some of the lighter more expensive diamonds. But eventually the weight of the diamonds drives the price up regardless of the quality of 'cut', as we can see from the three orange dots in the top right of the plot. These are of the lowest quality cut, but are the three heaviest diamonds in the dataset, and so end up being expensive.

### Interactions 

As we have 3 categorical variables: color, clarity and cut with 7, 8 and 5 levels respectively we have 280 separate interactions in our data set. This makes it likely that there will be unknown classes in our data. 

### Simple and Multiple Regression 

As we are interested in predicting price we thought it would be appropriate to do an initial multiple regression including all variables to see which are thought to be significant in predicting price when all other variables are included in the model. We have done this firstly with the raw variables and then with scaled versions of the variables.

# Simple linear regression using 'carat'

```{r, echo=FALSE}
carpricecor <- signif(cor(diamonds$carat, diamonds$price),4)
carpricecor
```

We theorised that 'carat' would be a very good predictor of 'price' based on the fact that 'carat' was the variable most highly correlated with 'price', with a correlation of `r carpricecor`between the two variables. Here we fit a simple linear regression model using 'carat' as the sole predictor variable. 

```{r}
# fit the linear regression model
carat.lm <- lm(price~carat, data = diamonds, x=T)

# display summary
summary(carat.lm)

# get anova table of linear regression model
anova(carat.lm)
```

```{r, echo=FALSE, results='hide'}
# sandpit for extracting values from model. will not show in rendered pdf
carlmsumm <- summary(carat.lm)
caranova <- anova(carat.lm)
carlmsumm[[10]]
carlmsumm[[11]]

F_stat <- caranova[[4]][1]
F_stat

caranova
caranova[[5]][1]

```


The output from the linear regression model above shows that 'carat' is a good predictor of 'price'. The t-test statistic is `r F_stat`, which is an enormous number, and the p-value is `r caranova[[5]][1]`. So, with a p-value of zero, we have very strong evidence to say that 'carat' is a good predictor of 'price'. 

## Testing to find the best regression model

### The Akaike Information Criterion (AIC) test
We now use the Akaike Information Criterion (AIC) stepwise regression test in R to find the best regression model that has 'price' as the response variable. We are particularly interested in whether any other models outperform the simple 'carat' model.

```{r}
# fit the linear regression model with all predictors
full.lm <- lm(price ~ .,data = diamonds)

# display the model summary
summary(full.lm)

# use the step() function to perform the stepwise AIC test
step(full.lm, direction = "both")
```

Based on the output from the stepwise AIC regression comparison above, the best model which balances accuracy against parsimony is the one with predictors carat + cut + color + clarity + depth + table + x. In other words, the predictors that were dropped are y and z. The AIC value for this model is 758425 compared with 758426 for the next best. The difference between the two is only 1, but the principle of parsimony dictates that we select the simplest model, which means selecting the one that drops the variable 'y'. 

### Bayes Information Criterion (BIC) model comparison

```{r}
# store the sample size in a variable 
n <- length(diamonds$price)

# repeat the step test with the added 'k' argument to perform the BIC
step(full.lm, direction = "both", k=log(n))
```

The model comparison using the Bayes Information Criterion (BIC) confirms that the best model is the one with variables carat + cut + color + clarity + depth + table + x (output above). The BIC value for this model is 758621, compared with 758629 for the next best. 

## Fitting the best model

The 'best' model (as found by the AIC test above) is fitted below.

```{r}
best.lm <- lm(price ~ carat + cut + color + clarity +
                depth + table + x, data = diamonds)

summary(best.lm)

```

The summary output for the 'best' model above shows how the categorical variables, all of which measure diamond quality, add a lot to the accuracy of the model. For example, 'Clarity', which has 8 levels, adds from 2702.077 (lowest quality clarity) to 5344.338 (highest quality clarity) to price depending on which level the diamond is categorised at. This is a wide range and cannot be obtained with these categorical variables dropped from the model.

## Check Regression Assumptions


```{r}
par(mfrow=c(2,2))
plot(best.lm, 1)
plot(best.lm, 2)
plot(best.lm, 3)
plot(best.lm, 4)
```

By examining the residual plots we see that it is likely that the assumptions underlying a multiple linear regression such as linearity, homogeneity of the variance and normality of the residuals are violated. There also appears to be a number of points with high leverage and influence. We should therefore be cautious in concluding much from this regression model. 

## Scaled multiple regression model

In this version we scale the variables. 

```{r}
diamondslm <- lm(price ~ scale(carat) + scale(x) + scale(y) + scale(z) + scale(depth) + scale(table) + cut + clarity + color, data = diamonds)
summary(diamondslm)
```

An initial multiple regression indicates that all variables but y and z are significant in the model (once the effect of the other predictors has been accounted for). This model accounts of 91.98% of the variation in the data.  



# Principal Component Analysis

We will perform a PCA with the aim of being able to explain the variation in the data set with fewer dimensions. We also hope to then create a parsimonious model for predicting diamond price through principal components regression.


```{r}
pca.diamonds <- prcomp(subset(diamonds.df, select = c(1,5:10)),
                       center=TRUE, scale. = TRUE, retx=TRUE)
plot(pca.diamonds)
summary(pca.diamonds)
```

We see that the first principal component explains the majority of the variance (68%) in the dataset with second (18%) and third (10%) principal components explaining a noticeable amount. Components beyond the third principal component explain minimal variance (less than 4%). This indicates we can describe the data using only the first two or three principal components without losing much information. We will now examine which variables contribute most strongly to each Principal Component. 


```{r}
pca.diamonds$rotation
```

Looking at the eigenvectors we see that PC1 is primarily defined by carat, price, x, y and z. PC1 seems to be defined by dimension variables and, as we saw in the correlation matrix, price is closely associated with these variables. The variables with the most weight in PC2 are depth and table. We see a similar pattern in PC3 with depth and table having the largest weighting. This makes sense as in our examination of correlations between variables we saw that price, x, y, z and carat were all strongly correlated. The opposite loadings of depth and table in PC2 and PC3 reflect there negative correlation.  A visualization of the PCA is shown in the Biplot below. 


```{r}
ggbiplot(pca.diamonds, obs.scale =1, var.scale = 1)
```

Due to the vast number of data entries it is hard to interpret what is going on from the visual display. We will not take a smaller sample of 1000 from the diamonds data and redo the PCA after first checking that the smaller sample has similar properties to the full sample. Also of note in this biplot are two significant outliers to the far right, which are extreme values of PC1. We shall idetify those before creating the smaller sample.

## Identify the extreme PC1 values

```{r}
sort(decreasing=T,(pca.diamonds$x[,1]))[1:10]
```

## PCA with Smaller Sample

```{r}
set.seed(300525287, kind = "Mersenne-Twister")
smallersample <- diamonds[sample(nrow(diamonds), "1000"), ]
reducedpca <- prcomp(smallersample[,-c(2:4,11)], center = TRUE, scale = TRUE)
```

```{r}
plot(reducedpca)
summary(reducedpca)
```

We see that the PCA with a sample size of 1000 has almost identical properties to the PCA of the whole dataset.

```{r}
ggbiplot(reducedpca, obs.scale =1, var.scale = 1, varname.size = 5)
```


We see that carat, x, y, z and price are strongly influence the first PC. While depth and table strongly (and reasonably equally) influence the second PC. We see evidence of the negative correlation between table and depth and a close to zero correlation between these two variables and the variables that strongly influence PC1. We also have an indication that there is redundancy between carat, x, y, z and price.  The percentage of variation retained by each Principal Component is included in the axis labels.

In this investigation we are interested in predicting the price of diamonds. To do this we will perform a regression with principal components with price as the dependent variable and the other numerical variables as explanatory variables. 

## Principal Components Regression

We will now perform a principal regression analysis with price as the response variable and and all other numerical variables as the explanatory variables. We Will again use the smaller sample to increase the ease of interpretation of the visual plots. 

```{r}
PCAprice <- prcomp(smallersample[,-c(2:4,7,11)], center = TRUE, scale = TRUE)
plot(PCAprice)
summary(PCAprice)
```

The plot above shows the proportion of variation explained by each of the principal components. The first three principal components explain nearly all (99%) the variation in the data.

```{r}
PCAprice$rotation
```

We see that in the first PC carat, x, y and z all have approximately equal weighting. Again this reflects the strong positive correlation between these two varaibles. In the second PC depth and table have the strongest weighting. We see that removing price from the PCA does not change much in terms of how much variation the first few components explain as well as which variables contribute most strongly to each component. This is because of how strongly price is correalted with the dimension variables

```{r}
ggbiplot(PCAprice, obs.scale =1, var.scale = 1, varname.size = 5)
```

Even with price not included we still see the same general structure as the PCA with price.

```{r}
PCApricevars <- prcomp(smallersample[,-c(2:4,7,11)], center = TRUE, scale = TRUE)$x
diamondpricePCA <- lm(smallersample$price ~ PCApricevars[,1] + PCApricevars[,2] + PCApricevars[,3] + PCApricevars[,4] + PCApricevars[,5] + PCApricevars[,6])
summary(diamondpricePCA)
```

We see that every single principal component is found to be significant in this model when the effects of the other principal components is taken into account. Therefore initially it seems we have failed to create a more parsimonious model for predicting price through using regression with principal components. However if we refit the model with just the first two principal components (see below) we still create a model that is able to explain over 81% of the variance in price with only two components. While this is not as good as the model with all the principal components (which explains 85%) it is still reasonably good and is much more simple. The original multiple regression model explained 91% of the variation in price with 9 explanatory variables while our PCR model explains 81% with just the first two principal components.

```{r}
diamondpricePCA2 <- lm(smallersample$price ~ PCApricevars[,1] + PCApricevars[,2])
summary(diamondpricePCA2)
```


It is likely that the remaining, unexplained variation could be explained by the categorical variables in the dataset. As Principal Components Analysis/Regression can only be used for numerical variables we had to leave out the variables of cut, clarity and color.


## Factor Analysis

In our investigation of the principal components of the dataset we observed that the first two principal components explained the the vast majority of the variation in the data.  The first was dominated by the strong positive correlation between price and the dimension variables (x, y, z, carat) which we may call price + dimension. The second was the negative correlation between depth and table which we might combine into light performance as both variables are crucial in giving a diamond its "sparkle". We hypothesise that these two factors (1. "Price + Dimension" 2. "Light Performance") may explain the observations in the diamonds dataset. To investigate this we will conduct an exploratory factor analysis with two factors.  

```{r}
factanal(diamonds[,-c(2:4,11)], factors =2)
```

As we hypothesized Carat, price, x, y and z are well explained by factor 1. Depth is very well explained by factor 2 but table is to a lesser degree. We see some evidence of the factor structure in our hypothesis with the "price + dimension" variables strongly implicated in Factor 1 and "Light conductance" variables most strongly explained by factor 2. However, we also see other original variables we did not expect in each of our factors. Factor 1 explains 66% of the variance in the data and Factor 2 explains an additional 16%. We also see high uniqueness ratings for table indicating that the two factors do not well account for it's variance. 

Overall the hypothesis test gives a highly significant result meaning that two factors is not sufficient to capture the full dimensionality of the data set.

# Linear Discriminant Analysis (LDA)

As discussed previously the diamonds dataset has three categorical variables each with many levels. This means we have the possibility of 280 unique interactions between the levels of these categorical variables. We will attempt too use Linear Discriminant Analysis to classify observations more simply using one of the categorical variables at a time.

```{r}
set.seed(300525287, kind = "Mersenne-Twister")
ind <- sample(c("Train", "Test"),
              nrow(smallersample),
              replace = TRUE, 
              prob = c(.6, .4))
diamonds.Train <- smallersample[ind == "Train",]
diamonds.Test <- smallersample[ind == "Test",]
LDAcut <- lda(cut ~ carat + depth + table + price
              + x + y + z, data = diamonds.Train)
LDAcolor <- lda(color ~ carat + depth + table + price
                + x + y + z, data = diamonds.Train)
LDAclarity <- lda(clarity ~ carat + depth + table + price
                  + x + y + z, data = diamonds.Train)
```


We see that mean carat and mean price seem to differ the most across levels of "cut". In LD1 x and y weight significantly more than the other variables.  

```{r ordplot, fig.cap="Ordination plot"}
library(ggord)

g1 <- ggord(LDAcut, diamonds.Train$cut, alpha = 0.5, )
g2 <- ggord(LDAcolor, diamonds.Train$color, alpha = 0.5 )
g3 <- ggord(LDAclarity, diamonds.Train$clarity, alpha = 0.5)
ggarrange(g1, g2, g3, ncol = 2, nrow =2)
```

All three ordination plots (figure \@ref(fig:ordplot)) show a lot of overlap between different levels of the categorical variables. It seems unlikely that a linear discriminant function would have much success in partitioning the data according to these classes. We shall compute the confusion matrix for each LDA and assess the overall accuracy of each model.

```{r}
RPcut <- predict(LDAcut, diamonds.Test)$class
RCMcut <- table(RPcut, actual = diamonds.Test$cut)
RPcolor <- predict(LDAcolor, diamonds.Test)$class
RCMcolor <- table(RPcut, actual = diamonds.Test$color)
RPclarity <- predict(LDAclarity, diamonds.Test)$class
RCMclarity <- table(RPcut, actual = diamonds.Test$clarity)
```

```{r}
Cutacc <- sum(diag(RCMcut))/sum(RCMcut)
Coloracc <- sum(diag(RCMcolor))/sum(RCMcolor)
Clarityacc <- sum(diag(RCMclarity))/sum(RCMclarity)
```

**Table: Classification Accuracy for Different LDA's**

\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 Class & Accuracy \\ 
  \hline
Cut & 0.6382\\
Color & 0.196  \\
Clarity & 0.1457\\
   \hline
\end{tabular}
\end{table}

In the table above we see the only categorical variables the LDA has any sucess of classifying is "cut". For color and clarity the LDA performs very poorly indeed. We conclude that it is likely that the classes (particularly for clarity and color) are not linearly seperable. 


## Why prediction without the categorical variables is not working well

### Create modified version of dataset only containing carat values between 1 and 1.1

```{r, warning=FALSE, message=FALSE}
library(dplyr)
diamonds_car2 <- diamonds[,c(1,4,7)]
diamonds_car2[1:4,]
diamonds_car19_21 <- filter(diamonds_car2, between(carat, 1, 1.1))
diamonds_car19_21[1:4,]
```




```{r carat1to11clarity, fig.cap="Carat (limited values) vs Price coloured by Clarity"}

# scatterplot of carat vs price, but also colouring the observations
# by 'cut'
ggplot(data=diamonds_car19_21, aes(x=carat, y=price, color=clarity))+
  geom_point()+
  guides(colour=guide_legend(reverse = T))+
  labs(title = "'Carat' vs 'price', coloured by 'clarity'")
```

Figure \@ref(fig:carat1to11clarity) shows a the scatterplot of 'price' vs 'carat' vs 'clarity', but just for values of 'carat' between 1 and 1.1, which helps us see the pattern more clearly. Firstly, note the vertical spread of the data points; most of the values begin at around 2500 USD and generally have extreme upper values larger than 15,000 USD, so a spread of approximately 10,000 USD. There are clear colour bands running horizontally, with the lowest quality 'clarity' diamonds near the bottom of the price range, while the highest values are near the top.

So, using 'carat' alone to predict these prices clearly is not enough; given the spread of price for any given value of carat, the categorical variables play an important in determining where in the range any given diamond will be. This was the reason our regression models that excluded the categorical variables did not perform nearly as well as those that included them.

## Discriminant analysis using the reduced dataset (price, carat and clarity)

```{r}
# split dataset into 'train' and 'test'
set.seed(1234567890, kind = "Mersenne-Twister")
ind <- sample(c("Tr","Te"),
              nrow(diamonds_car19_21),replace = TRUE,prob = c(0.6,0.4))

# display first few elements to check
ind[1:15]
```

```{r}
# check that the proprortions have come out as expected
nrow(diamonds_car19_21)
table(ind)
prop.table(table(ind))
```

The output above confirms that the random allocation of values to either the training or testing datasets produced the desired result of approximately 60% in the training set and 40% in the testing set. 

### Create training and test subsets

```{r}
Train <- diamonds_car19_21[ind=="Tr",]
Test <- diamonds_car19_21[ind=="Te",]

```

### Create LDA and display summary

```{r}
library(MASS)
LDA.diam <- lda(clarity~carat+price,
           data=Train)

```

### Boxplots of the LDA means

```{r ldameans, fig.cap="Distribution of LDA means"}
boxplot(t(LDA.diam$means), main=
          "Distribution of LDA means for each level of 'clarity'",
        xlab="Levels of 'clarity' (lowest on the left, highest on the right)",
        ylab="Count")
```

Figure \@ref(fig:ldameans) shows the distribution of the LDA means. It is obvious that there is an increasing number of diamonds of higher 'clarity' levels.

### Create Prediction object

```{r}
Pred <- predict(LDA.diam)

```

### Biplot

```{r biplot2, fig.cap="Biplot of 'carat', 'price' against 'clarity'"}
library(klaR)
library(ggord)
library(devtools)
ggord(LDA.diam,Train$clarity)
```

Figure \@ref(fig:biplot2) shows the biplot for 'carat' versus 'price' against the different levels of 'clarity'.  

### Partition plot

```{r partplot2, fig.cap="Partition plot for levels of 'clairty' as predicted by 'carat' and 'price'"}
partimat(clarity~carat+price, data = Train, method="lda")
```

Figure \@ref(fig:partplot2) shows the partition plot for the discriminant analysis (DA) of the different levels of the 'clarity' variable as predicted by 'carat' and 'price'. As a reminder, the levels are (from lowest to highest): Fair, Good, Very Good, Premium and Ideal.  


```{r}
RealisticPredicted <- predict(LDA.diam,Test)$class
RCM <- table(RealisticPredicted, Actual=Test$clarity)
RCM
```

The confusion matrix above shows that there were many mis-categorisations. There is a pattern evident. The leading diagonal shows the correct predictions. There are many incorrect predictions for values immediately above and below the leading diagonal, meaning that the DA partitions struggled to separate adjacent categories. 

```{r}
prop_succ <- sum(diag(RCM))/sum(RCM)
prop_succ

per_succ <- signif(prop_succ*100,4)
per_succ
```

The output above shows that the percentage of successful predictions was `r per_succ`%, indicating that this LDA is a mediocre predictor. 

### Summary of LDA

The relatively poor performance of LDA in this instance is perhaps not surprising given the amount of overlap we saw in figure \@ref(fig:carat1to11clarity) earlier (the scatterplot of 'price' vs 'carat' vs 'clarity' for 'carat' values between 1 and 1.1); there simply isn't enough geometrical separation between the different levels of 'clarity' for the algorithm to accurately categorise the boundary cases.

# Cluster Analysis

As LDA did not yield useful results in terms of classifying the diamonds data we also decided to conduct Cluster Analysis to see if the diamonds data set could be divided into groups. We used a K-means algorithm to achieve this. As we were initially unsure of how many clusters we should attempt to divide the data into we will first examine the sum of the squares of the intra-class disatances for different numbers of clusters. 

### Optimal cluster number

```{r optclust, fig.cap="Optimal number of clusters"}
fviz_nbclust((scale(smallersample[,-c((2:4),11)])), kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")
```

Figure \@ref(fig:optclust) shows that when the elbow method is used, we see that 4 clusters is the optimum number.

### kmeans function

```{r}
clusters <- kmeans(scale(smallersample[,-c((2:4),11)]), 
                   algorithm = "MacQueen", centers = 4, 
                   iter.max = 100, nstart = 50)

# print clusters means
clusters$centers

# print first 20 values
clusters$cluster[1:20]


```

We create four clusters with sizes of 127, 455, 137 and 281 respectively. We see clear differences in the mean of each numeric variable across the four clusters. The within cluster sum of squares indicates that the clusters are not very compact. We shall now visualize the clusters with a scatterplot using the first two principal components of our dataset as the two dimensions. The first two principal components account for over 86% of the variance so this should be an appropriate visualization.

### Cluster plot

```{r clustplot, fig.cap="Cluster plot"}
fviz_cluster(clusters, data = (scale(smallersample[,-c((2:4),11)])),
             geom = "point",
             ellipse.type = "norm", 
             ggtheme = theme_bw()
             )
```

In the cluster plot (figure \@ref(fig:clustplot)) we see significant overlap between the four clusters as well as many observations that do not seem to fit well in any of the clusters. It seems that the diamond dataset does not easily split into distinct clusters.

### Silhouette plot

```{r silh, fig.cap="Clusters silhouette plot"}
library(cluster)
sil <- silhouette(clusters$cluster, dist((scale(smallersample[,-c((2:4),11)]))))
fviz_silhouette(sil)
```

The silhouette plot (figure \@ref(fig:silh)) helps us to visualize how similar points each observation is to the cluster that it is assigned too. We see very few negative values indicating that very few observations have been assigned to the wrong cluster. However we do have a large proportion of values with low positive values indicating that these observations were close to the borderline between two clusters. We see that the average silhouette width is 0.38. 

# Conclusions



# Appendices

## Code for Producing KS Tests

```{r, include = FALSE }
ks.test(diamonds$carat, "pnorm", mean=mean(diamonds$carat), sd=sd(diamonds$carat))
ks.test(diamonds$depth, "pnorm", mean=mean(diamonds$depth), sd=sd(diamonds$depth))
ks.test(diamonds$table, "pnorm", mean=mean(diamonds$table), sd=sd(diamonds$table))
ks.test(diamonds$price, "pnorm", mean=mean(diamonds$price), sd=sd(diamonds$price))
ks.test(diamonds$x, "pnorm", mean=mean(diamonds$x), sd=sd(diamonds$x))
ks.test(diamonds$y, "pnorm", mean=mean(diamonds$y), sd=sd(diamonds$y))
ks.test(diamonds$z, "pnorm", mean=mean(diamonds$z), sd=sd(diamonds$z))
```


## Code for producing ANOVA/Levene's Test/Kruskal Wallis/Tukey of Price by Cut

```{r, include = FALSE}
cutanova <- aov(price ~ cut, data = diamonds)
summary(cutanova)
leveneTest(price ~ cut, data= diamonds)
kruskal.test(price ~ cut, data = diamonds)
TukeyHSD(cutanova, conf.level = 0.95)
```

## Code for producing ANOVA/Levene's Test/Kruskal Wallis/Tukey of Price by Clarity

```{r, include = FALSE}
clarityanova <- aov(price ~ clarity, data = diamonds)
summary(clarityanova)
leveneTest(price ~ clarity, data= diamonds)
kruskal.test(price ~ clarity, data = diamonds)
TukeyHSD(clarityanova, conf.level = 0.95)
```

##  Code for producing ANOVA/Levene's Test/Kruskal Wallis/Tukey of Price by Color

```{r, include = FALSE}
coloranova <- aov(price ~ color, data = diamonds)
summary(coloranova)
leveneTest(price ~ color, data= diamonds)
kruskal.test(price ~ color, data = diamonds)
TukeyHSD(coloranova, conf.level = 0.95)
```

# Bibiography
